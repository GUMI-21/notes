+ CNN
*卷积核*：CNN的卷积核就是一个小矩阵，这个小矩阵在扫描图像的时候相当于根据图像数据的占比权重提取特征数据， “特征探测器”。 图像数据：如果是彩色的就是RGB `H x W x 3` 三维矩阵， 如果是灰度的就是HXW 二维矩阵，我觉得这有点类似Linear algebra中介绍的图像压缩方法。
-在图像压缩中，我们用SVD/PCA 提取图像中最重要的主成分，去掉冗余
-在CNN中，卷积核可以理解为自动学习出来的特征基底，提取边缘、纹理等不同方向的特征 -都在做线性组合
-CNN可以理解为 “线性代数+局部提取+非线性变换”的图像特征编码系统

*卷积层*： Convolutional Layer -> outpu is Feature Map（特征图）
👉 通常是多个卷积核叠加，所以一个卷积层会输出多张特征图（channel 增多）
*激活函数层（Activation Layer）*：✅ 常用的是 ReLU（Rectified Linear Unit）- 把负值砍掉，正值保留，引入非线性。 位置不变，但特征图更“稀疏”，只保留重要响应
*池化层（Pooling Layer），也叫下采样层（Subsampling）*： - 降低特征图尺寸（比如从 32x32 → 16x16）- 提取“区域最强特征”或“平均特征” - 减少参数、提升鲁棒性

大多数 CNN 是： 卷积层 + 激活层 + 池化层 反复堆叠

*全连接层（Fully Connected Layer, FC）*：- 把最后一层卷积输出的“特征图”**展开成一个长向量**（Flatten） - 接一个或多个全连接层（Linear 层），进行最终分类或回归任务
*Softmax（输出层）：* 把输出向量变成“概率分布”，每个值表示属于某类的概率。